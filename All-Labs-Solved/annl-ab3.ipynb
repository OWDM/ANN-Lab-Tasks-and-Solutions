{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1"
      ],
      "metadata": {
        "id": "fixmb0uC3426"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpVBTNtJ3zSi",
        "outputId": "ec67502b-21be-4c3a-ac8d-d4c3b35cc1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15]\n",
            " [34]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def feedforwardlayer(p, w, b):\n",
        "    n = np.dot(w, p) + b\n",
        "    a1 = purelin(n)\n",
        "    return a1\n",
        "\n",
        "def purelin(n):\n",
        "    return n  # This is the identity function, acting as the transfer function (purelin)\n",
        "\n",
        "# Example usage\n",
        "p = np.array([[1], [2], [3]])  # Column vector p\n",
        "w = np.array([[1, 2, 3], [4, 5, 6]])  # Weight matrix w\n",
        "b = np.array([[1], [2]])  # Bias vector b\n",
        "\n",
        "a1 = feedforwardlayer(p, w, b)\n",
        "print(a1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2"
      ],
      "metadata": {
        "id": "bz8jJVSy387f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def feedforwardlayer(p, w, b):\n",
        "    n = np.dot(w.T, p) + b\n",
        "    a1 = purelin(n)\n",
        "    return a1\n",
        "\n",
        "\n",
        "def purelin(n):\n",
        "    return n  # This is the identity function, acting as the transfer function (purelin)\n",
        "\n",
        "\n",
        "# Prototype patterns\n",
        "po = np.array([[1], [-1], [-1]])\n",
        "pa = np.array([[1], [1], [-1]])\n",
        "\n",
        "# Weight matrix\n",
        "W1 = np.hstack((po, pa))  # [po, pa]\n",
        "\n",
        "# Bias vector\n",
        "b1 = np.array([[3], [3]])\n",
        "\n",
        "# Input vector\n",
        "p = np.array([[1], [1], [-1]])\n",
        "\n",
        "# Feedforward\n",
        "a1 = feedforwardlayer(p, W1, b1)\n",
        "print(a1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjQuGnfF3-Bw",
        "outputId": "8c3f4986-4d73-4a18-f39f-ca243b3b3d72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4]\n",
            " [6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3"
      ],
      "metadata": {
        "id": "X7UF9-PY4BDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def recurrentlayer(t, a, W):\n",
        "    if t == 0:\n",
        "        a2 = a\n",
        "    else:\n",
        "        a2 = poslin(np.dot(W, a))\n",
        "    return a2\n",
        "\n",
        "def poslin(x):\n",
        "    return np.maximum(0, x)  # ReLU activation function (poslin)\n",
        "\n",
        "# Example usage\n",
        "t = 1  # Timestep\n",
        "a1 = np.array([[4], [2]])  # Output of the first layer (a1)\n",
        "\n",
        "# Weight matrix\n",
        "W2 = np.array([[1, -0.5], [-0.5, 1]])\n",
        "\n",
        "# Recurrent layer\n",
        "a2 = recurrentlayer(t, a1, W2)\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEpQNYQa4C1Y",
        "outputId": "5b9728fc-e6ad-4c29-d8f8-6245d5ac1bea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4"
      ],
      "metadata": {
        "id": "gOOFeEkt4Giq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def recurrentlayer(t, a, W):\n",
        "    if t == 0:\n",
        "        a2 = a\n",
        "    else:\n",
        "        a2 = poslin(np.dot(W, a))\n",
        "    return a2\n",
        "\n",
        "\n",
        "def poslin(x):\n",
        "    return np.maximum(0, x)  # This is the ReLU activation function (poslin)\n",
        "\n",
        "\n",
        "# Weight matrix\n",
        "S = 2  # Number of neurons\n",
        "𝜺 = 1 / (S - 1)\n",
        "W2 = np.array([[1, -𝜺], [-𝜺, 1]])\n",
        "\n",
        "# Initial output of the first layer (a1)\n",
        "a1 = np.array([[4], [2]])\n",
        "\n",
        "# Table for t = 0, 1, 2\n",
        "table = []\n",
        "for t in range(3):\n",
        "    a2 = recurrentlayer(t, a1, W2)\n",
        "    table.append((t, a1.flatten(), a2.flatten()))\n",
        "\n",
        "# Print the table\n",
        "print(\"t\\t a1\\t\\t a2\")\n",
        "for row in table:\n",
        "    t, a1_val, a2_val = row\n",
        "    print(f\"{t}\\t {a1_val}\\t {a2_val}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCxdX7sa4IGB",
        "outputId": "d7530263-c155-4781-aaa7-0f46be13cc8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t\t a1\t\t a2\n",
            "0\t [4 2]\t [4 2]\n",
            "1\t [4 2]\t [2. 0.]\n",
            "2\t [4 2]\t [2. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5"
      ],
      "metadata": {
        "id": "S1aeus3K4OgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def poslin(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def feed_forward_layer(P, W, B):\n",
        "    X = np.dot(W, P) + B\n",
        "    return X\n",
        "\n",
        "def recurrent_layer(A1, W, T):\n",
        "    if T == 0:\n",
        "        return A1\n",
        "    else:\n",
        "        A2 = A1\n",
        "        for i in range(1, T+1):\n",
        "            N = np.dot(W, A2)\n",
        "            A = [poslin(item) for item in N]\n",
        "            A2 = A\n",
        "        return A2\n",
        "\n",
        "W1 = np.array([[1, -1, -1], [1, 1, -1]])\n",
        "B1 = np.array([3, 3])\n",
        "W2 = np.array([[1, -0.5], [-0.5, 1]])\n",
        "T = 1\n",
        "\n",
        "inputs = [\n",
        "    np.array([1, 1, 1]),\n",
        "    np.array([1, 1, -1]),\n",
        "    np.array([1, -1, 1]),\n",
        "    np.array([1, -1, -1]),\n",
        "    np.array([-1, 1, 1]),\n",
        "    np.array([-1, 1, -1])\n",
        "]\n",
        "\n",
        "for p in inputs:\n",
        "    a1 = feed_forward_layer(p, W1, B1)\n",
        "    a2 = recurrent_layer(a1, W2, T)\n",
        "    print(f\"Input: {p}  a2(1): {a2}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Additional code for T=2\n",
        "T = 2\n",
        "\n",
        "for p in inputs:\n",
        "    a1 = feed_forward_layer(p, W1, B1)\n",
        "    a2 = recurrent_layer(a1, W2, T)\n",
        "    print(f\"Input: {p}  a2(2): {a2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5i1xB-u4Pxs",
        "outputId": "850eb453-ccdf-42cb-a6cf-3c1fb30f99bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [1 1 1]  a2(1): [0.0, 3.0]\n",
            "Input: [ 1  1 -1]  a2(1): [1.0, 4.0]\n",
            "Input: [ 1 -1  1]  a2(1): [3.0, 0.0]\n",
            "Input: [ 1 -1 -1]  a2(1): [4.0, 1.0]\n",
            "Input: [-1  1  1]  a2(1): [0.0, 2.0]\n",
            "Input: [-1  1 -1]  a2(1): [0.0, 3.0]\n",
            "\n",
            "Input: [1 1 1]  a2(2): [0.0, 3.0]\n",
            "Input: [ 1  1 -1]  a2(2): [0.0, 3.5]\n",
            "Input: [ 1 -1  1]  a2(2): [3.0, 0.0]\n",
            "Input: [ 1 -1 -1]  a2(2): [3.5, 0.0]\n",
            "Input: [-1  1  1]  a2(2): [0.0, 2.0]\n",
            "Input: [-1  1 -1]  a2(2): [0.0, 3.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5 second way"
      ],
      "metadata": {
        "id": "-S_nfP2s5G-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "\n",
        "def feedforward_layer(W1, B1, p):\n",
        "  \"\"\"Computes the output of the feedforward layer.\"\"\"\n",
        "  a1 = np.dot(p, W1.T) + B1\n",
        "  a2 = np.where(a1 >= 0, 1, -1)\n",
        "  return a2\n",
        "\n",
        "def recurrent_layer(W2, a2):\n",
        "  \"\"\"Computes the output of the recurrent layer.\"\"\"\n",
        "  a3 = np.dot(a2, W2)\n",
        "  return a3\n",
        "\n",
        "def hamming_network(W1, B1, W2, p):\n",
        "  \"\"\"Computes the output of the complete Hamming network.\"\"\"\n",
        "  a2 = feedforward_layer(W1, B1, p)\n",
        "  a3 = recurrent_layer(W2, a2)\n",
        "  while not np.array_equal(a2, a3):\n",
        "    a2 = a3\n",
        "    a3 = recurrent_layer(W2, a2)\n",
        "  return a3\n",
        "\n",
        "# Test the Hamming network with the given parameters and input values.\n",
        "W1 = np.array([[1, -1, -1], [1, 1, 1]])\n",
        "B1 = np.array([[3], [3]])\n",
        "W2 = np.array([[1, -0.5], [-0.5, 1]])\n",
        "\n",
        "inputs = [[1, 1, 1], [1, 1, -1], [1, -1, 1], [1, -1, -1], [-1, 1, 1], [-1, 1, -1]]\n",
        "outputs = []\n",
        "\n",
        "for p in inputs:\n",
        "  output = hamming_network(W1, B1, W2, p)\n",
        "  outputs.append(output)\n",
        "\n",
        "# Print the output of the Hamming network in a table.\n",
        "print(tabulate([[\"Input (p)\", \"a2(1)\", \"a2(2)\"]] + [[p[0], p[1], p[2]] for p in inputs], headers=[\"Input (p)\", \"a2(1)\", \"a2(2)\"], tablefmt=\"pipe\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oqqkNwP5La3",
        "outputId": "f6725fba-756c-485d-fda1-a5b7fa44f33c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Input (p)   | a2(1)   | a2(2)   |\n",
            "|:------------|:--------|:--------|\n",
            "| Input (p)   | a2(1)   | a2(2)   |\n",
            "| 1           | 1       | 1       |\n",
            "| 1           | 1       | -1      |\n",
            "| 1           | -1      | 1       |\n",
            "| 1           | -1      | -1      |\n",
            "| -1          | 1       | 1       |\n",
            "| -1          | 1       | -1      |\n"
          ]
        }
      ]
    }
  ]
}